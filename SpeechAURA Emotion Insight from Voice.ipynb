{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source \n",
    "# https://learnpython.com/blog/plot-waveform-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:29:38.454312Z",
     "iopub.status.busy": "2023-08-04T03:29:38.453828Z",
     "iopub.status.idle": "2023-08-04T03:29:38.486235Z",
     "shell.execute_reply": "2023-08-04T03:29:38.485589Z",
     "shell.execute_reply.started": "2023-08-04T03:29:38.454272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the path to the audio file\n",
    "audio_file_path = \"/fitzingout/proxmoxve/datasets/UrbanSodcdc/audio/fold1/101415-3-0-2.wav\"\n",
    "\n",
    "# Open the audio file\n",
    "wav_obj = wave.open(audio_file_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:31:37.529888Z",
     "iopub.status.busy": "2023-08-04T03:31:37.529498Z",
     "iopub.status.idle": "2023-08-04T03:31:37.535033Z",
     "shell.execute_reply": "2023-08-04T03:31:37.534134Z",
     "shell.execute_reply.started": "2023-08-04T03:31:37.529859Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_freq = wav_obj.getframerate()\n",
    "n_samples = wav_obj.getnframes()\n",
    "duration = n_samples / sample_freq\n",
    "num_channels = wav_obj.getnchannels()\n",
    "print(\"Sample Frequency: {} \\nNumber of Samples: {} \\nDuration: {} \\nNumber of Channels: {}\".format(sample_freq, n_samples, duration, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:34:03.313776Z",
     "iopub.status.busy": "2023-08-04T03:34:03.313424Z",
     "iopub.status.idle": "2023-08-04T03:34:03.320037Z",
     "shell.execute_reply": "2023-08-04T03:34:03.318961Z",
     "shell.execute_reply.started": "2023-08-04T03:34:03.313749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the audio signals\n",
    "wave_signal = wav_obj.readframes(n_samples)\n",
    "signals = np.frombuffer(wave_signal, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:35:05.804118Z",
     "iopub.status.busy": "2023-08-04T03:35:05.803774Z",
     "iopub.status.idle": "2023-08-04T03:35:05.812195Z",
     "shell.execute_reply": "2023-08-04T03:35:05.809849Z",
     "shell.execute_reply.started": "2023-08-04T03:35:05.804090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the waveform\n",
    "times = np.linspace(0, duration, num=n_samples)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times, signals)\n",
    "plt.title('Visualization of audio file waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Signal value')\n",
    "plt.xlim(0, duration)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T04:24:34.470316Z",
     "iopub.status.busy": "2023-08-04T04:24:34.469963Z",
     "iopub.status.idle": "2023-08-04T04:24:34.478474Z",
     "shell.execute_reply": "2023-08-04T04:24:34.476594Z",
     "shell.execute_reply.started": "2023-08-04T04:24:34.470289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the audio file using librosa\n",
    "y, sr = librosa.load(audio_file_path)\n",
    "\n",
    "# Calculate MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:37:00.789562Z",
     "iopub.status.busy": "2023-08-04T03:37:00.789168Z",
     "iopub.status.idle": "2023-08-04T03:37:00.796195Z",
     "shell.execute_reply": "2023-08-04T03:37:00.794608Z",
     "shell.execute_reply.started": "2023-08-04T03:37:00.789521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot MFCCs\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCCs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:38:01.718789Z",
     "iopub.status.busy": "2023-08-04T03:38:01.718140Z",
     "iopub.status.idle": "2023-08-04T03:38:01.723850Z",
     "shell.execute_reply": "2023-08-04T03:38:01.722312Z",
     "shell.execute_reply.started": "2023-08-04T03:38:01.718752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select a specific frame (e.g., frame 10)\n",
    "frame_index = 10\n",
    "frame_mfccs = mfccs[:, frame_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T03:39:22.974135Z",
     "iopub.status.busy": "2023-08-04T03:39:22.973324Z",
     "iopub.status.idle": "2023-08-04T03:39:22.979398Z",
     "shell.execute_reply": "2023-08-04T03:39:22.977984Z",
     "shell.execute_reply.started": "2023-08-04T03:39:22.974091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar graph for the selected frame\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(len(frame_mfccs)), frame_mfccs, color='b', alpha=0.7)\n",
    "plt.xlabel('MFCC Coefficient Index')\n",
    "plt.ylabel('MFCC Value')\n",
    "plt.title(f'MFCCs for Frame {frame_index}')\n",
    "plt.xticks(range(len(frame_mfccs)))  # Label the x-axis with coefficient indices\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate metadata for Dataset so we can organize it\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = \"/path/to/your/dataset\"\n",
    "\n",
    "# Set the path for the generated metadata file\n",
    "metadata_path = \"/path/to/your/metadata.csv\"\n",
    "\n",
    "# Function to extract emotion class and level from file name\n",
    "def extract_info_from_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    emotion_class = parts[2]\n",
    "    emotion_level = parts[3].split('.')[0] if len(parts) > 3 else \"Unspecified\"\n",
    "    return emotion_class, emotion_level\n",
    "\n",
    "# Create an empty DataFrame to store metadata\n",
    "metadata_columns = ['filename', 'emotion_class', 'emotion_level']\n",
    "metadata_df = pd.DataFrame(columns=metadata_columns)\n",
    "\n",
    "# Process each audio file\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "\n",
    "            # Extract emotion class and level from the filename\n",
    "            emotion_class, emotion_level = extract_info_from_filename(filename)\n",
    "\n",
    "            # Load the audio file and extract MFCCs\n",
    "            try:\n",
    "                y, sr = librosa.load(file_path)\n",
    "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Choose an appropriate representation or summary of the MFCCs for further processing\n",
    "            mfcc_summary = mfccs.mean(axis=1)  # For example, using the mean of MFCCs\n",
    "\n",
    "            # Add information to the metadata DataFrame\n",
    "            metadata_df = metadata_df.append({\n",
    "                'filename': filename,\n",
    "                'emotion_class': emotion_class,\n",
    "                'emotion_level': emotion_level,\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            # Optionally, you can save the MFCC summary to a file for later use\n",
    "            mfcc_summary_path = os.path.join(root, f\"{os.path.splitext(filename)[0]}_mfcc_summary.npy\")\n",
    "            np.save(mfcc_summary_path, mfcc_summary)\n",
    "\n",
    "# Save the metadata to a CSV file\n",
    "metadata_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(\"Metadata generation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = \"/path/to/your/dataset\"\n",
    "\n",
    "# Set the path to your metadata file\n",
    "metadata_path = \"/path/to/your/metadata.csv\"\n",
    "\n",
    "# Load the metadata\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(file_path, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "        return mfccs_mean\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract MFCC features for each audio file\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "\n",
    "for index, row in metadata_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    emotion_class = row['emotion_class']\n",
    "\n",
    "    file_path = os.path.join(dataset_path, emotion_class, filename)\n",
    "    mfcc = extract_mfcc(file_path)\n",
    "\n",
    "    if mfcc is not None:\n",
    "        mfcc_features.append(mfcc)\n",
    "        labels.append(emotion_class)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "X = np.array(mfcc_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Encode the emotion labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
